# 面试讲稿

@Aiken 2021  

整理面试之中的自我介绍和项目介绍的部分，主要是对每一部分的工作进行梳理，明白自己到底要怎么讲自己做过的工作内容，和工作的亮点。

TIMELINE（整个介绍流程）

基础内容介绍，组里的工作介绍，以及**主要的研究方向**（Few-Shot Semi- Classification ）。然后

- 首先介绍毕设期间的工作（课题选择和我做的改进）基于BSN对Anchor-Based的较大影响进行测试，可以简单的引入一下数据处理模块的知识；
- 然后表示在做完毕设之后参与了人脸比对项目的开发，针对人脸比对过程中的算法选择进行了测试和分析，然后进行后续部署；（MXNET我要说嘛，还是说后续转回来了）
- 最后表示后续的研究工作：基于GCN在FSL中的尝试以及对标签传播上的研究，然后到EnAET半监督学习领域中的测试以及我对其的修正，后来到现在的这一部分工作，

## 工作内容介绍

### 项目1：AutoLoc

#### 讲稿：

毕设期间的第一个视觉相关的工作，然后学习了caffe，pytorch两种框架，其中在caffe的配置中遇到了一些问题，有一些配置要到caffe的源码中去修改，给实验带来了一些麻烦。

**工作介绍：**

[AutoLoc](https://zhuanlan.zhihu.com/p/63092925)

弱监督语义下的动作识别的算法的研究，这里的弱监督主要体现在：只有类别标签，但是没有准确的动作裁剪的这样一个场景。



**Temporal Segment Network 来提取特征** [TSN](https://blog.csdn.net/u014380165/article/details/79029309)

我使用预训练好的[**UntrimmedNet**](https://zhuanlan.zhihu.com/p/63163024)再作为提取特征的Backbone，然后将时间特征和空间特征链接形成2048-dim的特征向量 => 2048*T 的 feature map

Videos-> 每15帧提取一个clip -> 每个clip中**稀疏采样**一帧图像，两个光流特征图

然后Two-Stream Network 对这些Snippets提取整个视频特征，通过Spatial or Temporal ConvNet 来提取出两部分的特征序列（每个stream输出的是1024-dim的特征）。

**分类：**

输入将每个T映射到K个类别中的激活（预训练好的Untrimmed Net）FC-K得到一个Class Activation Sequence（T*K），对每个Class，使用一个Attention（fc-1）来作为类别激活的阈值（<直接将所有的类别的分数都置为0）

**定位：**

对2048\*T进行[Temporal Conv（same）+BN+ReLU] \*3后，进入Pred层（Class-agnostic），用2*Anchor个filiter 来生成预测：tx中心偏移量与，tw缩放anchor的系数；（对每个点）来获得最终的proposal的inner boundary；然后再稍微inflation得到 outer boundary，然后适用OIC loss 进行含有动作的概率进行度量，然后删除概率低的proposal。

对于每个片段来说的话：获得M个proposal，然后再CAS中找到对应的区域，小于阈值直接忽略，然后只保留其中OIC Loss最低的那个，同时也执行NMS IOU>0.4的删除。

**我的工作**

但是我们再实验中发现如果对Anchor进行稍微的修改的话，实际上效果下降得比较明显，也就是对于Anchor的依赖性太强了，所以基于BSN的研究，我们试图将该方法修改成一个Anchor-Free的架构，

跳转谈资2

#### 谈资1：几种不同思路的方法对比：

1. Hide-And-Seek：到逐步擦除逐步收集算法：基于图像上部分遮挡这样的一个思路，让算法能够学到次一级的outstanding的特征（避免陷入最的情况），将这样的思想拓展到视频层面；逐步擦除逐步收集是将最具区分度的部分剔除掉，然后结合连续的这个先验特征去做；

2. STPN：（这一部分太不熟了还是别写了）[LINK1](https://zhuanlan.zhihu.com/p/50943824)，实际上就是在分类的损失计算每一个和snippets中和每个类别之间的相关性；然后通过双流输入和之前对应帧数的注意力权重相乘，然后进行开始到结束时间段的平均激活求职，然后通过阈值来输出temporal propose。

3. UntrimmedNet：基于镜头变化的一致性（动作通常是的），然后就采取相邻帧的HOG特征的差异去分析的思想，然后就会检测到动作的变化，来做视频的初始切分；分为类别域和时间域的输出。基于分类的结果做一个Hard（多分类K）-Soft（Attention）的判断，来生成最终的结果


#### 谈资2：发现的问题和改进的原理和方式：

经过实验发现Anchor和数据集中的动作持续时长的相关性很强，也就是只有特定的两个Anchor 8、16 才有及格的输出，其他的时候算法的正确率会急剧下降，增大了感受野也不行，边界提议网络没有实际上的得到优化；

发现了对特定Anchor的依赖性太强了，划分的可靠性在我这里提出了一个质疑，就是到底能**不能通过OIC-LOSS真正的学习到对动作的切割**，为了泛化和拓宽这样算法的应用层面，也就是能够适应更多样的变化范围，于是我考虑到用BSN，边界敏感网络的结构来对其进行更新：

1. 没有改变算法的Backbone，也就是UntrimmedNet，而是修改了算法的时域卷积，为了算法对边界敏感网络的使用，采用时域上pooling以及简单的修改了卷积的参数（包括使用**空洞卷积**的策略和卷积参数的改变），来为后面的改进做了一个基础，拓宽了特征域上的感受野；

   > 再caffe 和pytorch中都是直接设置一下膨胀系数就行

2. 然后在前面的改进的基础上，我参考了**BSN**的思想，修改了算法的Anchor-Based机制，是的算法能够生成更加灵活的边界提议，能够对更灵活的边界进行适应和预估。

   我们基于BSN的基本思想，使得最终的优化目标改成一个动作作为开始的片段的概率和动作结束的概率，在原本的框架中进行修改，然后通过极大值和阈值的标准来选择，生成的proposal更加的灵活而且精细，对每个开始节点进行结尾的匹配

3. caffe遇到的问题：编译caffe的时候提示文件缺失：需要去别的版本的caffe中找，然后添加进来； 需要修改makefile.config里面的python_inlcude还是什么的值

#### 谈资3：重点算法原理：

空洞卷积实际上没啥好说的，就是在卷积的时候有一个扩张系数，让模型能有一个比较大的感受野，避免下采样，保留结构。

##### OIC_LOSS

通过类别激活概率特征的内部激活和外部激活之间的差异来执行

outer-inner

##### BSN（实现的方式）

参考了

- 动作的概率、开始的概率，结束的概率 
- 峰值、阈值、采样N个点拼接特征
- softnms

##### 空洞卷积，感受野

- 在这里空洞卷积的作用和感受野的作用。
- Padding的计算过程

#### 实验结果和分析：

正面分析：在IoU较低的情况下，算法的效果和AutoLoc基本持平，但是在IoU较高的情况下，对结果有一定的提升，这样的方法确实能够带来更精细的分类结果，但是在这样的弱监督的基础语境中，却没办法给算法带来进一步的提升。

![image-20210322202001833](https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210322202001833.png)

反面分析：对于最终的效果的提升的话，在这样的弱监督语境中，这些方法都没办法很好的衡量与最准确的动作边界的关系，算法的“弱监督”还是不够强。

![image-20210322201622550](https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210322201622550.png)

#### 代码细节和遇到的问题

- 在对模型进行修改的时候记得每次重新训练要修改名称，不然可能会直接导入之前的模型和参数，导致训练出现问题；
- 需要编写forward和backward，自定义的层继承caffe.layer
- 限定每个start-point的最大EndPoint数量，通过NMS和其他的机制（极大值和阈值），然后生成proposal
- python中的[,...]，然后根据回传后的数据维度去归一或者去改变后续传参中的数据维度
- tpl 写一个solver 写一个网络 type bottom top param

### 项目2：学信网的项目

我们对A-Softmax， Cos-Softmax ，Arc-Softmax进行了研究和实验....

公有测试数据集：LFW、CFP、age_db、非公有学信网测试数据集；

工作分工，通过resnet的架构来搭建基本主干网络，后续他们用沙漏网络HRNET来进行改进，此外，他们采用的是PCN的方式来对人脸的检测和对齐来做进一步的改进，更适应我们这种从角度去做图像分类的方法，

#### **Workflow**

**图像预处理**：使用im2rec将图像转成rec的二进制，然后通过数据流方式读取，首先生成im2rec生成.lst文件，同时也能进行train和val的划分，然后同样也还是通过im2rec来生成rec文件，然后就可以读取了。

[Im2Rec](https://blog.csdn.net/xiang_freedom/article/details/79871985)

本次实验的图片大小固定为112*112

使用mtcnn来进行人脸的对齐和检测，然后进行训练和测试；最后通过以后部署

**人脸检测和对齐**

用MTCNN检测人脸并resize，这一部分直接调用过来进行调整，但是有个问题就是这个对齐到人脸是啥意思

细节：需要调节MTCNN的三个网络层的阈值，将不存在人脸的图片筛选出来。

**需要注意的问题**

- 由于在模型训练时，我们使用的是SoftMax+CrossEntropy的分类损失函数，但是在测试时候，我们只需判断输入的两张图片是否属于同一个人，是一个二分类问题，所以不需要使用完整的模型结构。

- 测试的时候只需要：

  调用模型，输出模型的FC1层，即第一层全连接层，该层的输出是输入图片的512维feature-map的表示，对两张图片的feature-map做L2距离的计算，然后与阈值相比较：若L2距离大于阈值，则两者不属于同一个人，否则属于同一个人。

- 正负样例构建

- 训练的时候：按照总共又多少人来做最后类别的softmax训练

**模型部署**

使用mxnet-model-server来进行模型部署：handler相当于主函数，通过handl来组织整个使用流程，转格式，提取人脸，并进行比对。

> 其中handle函数需要被重载，调用模型的inference接口和处理数据的preprocess（）这两个子函数，在这里调用了mtcnn然后设置相应字段通过jason返回
>
> 在model_server中提供了一种标准的对inference的重载，我们使用了最终的输出所有就没有对这个进行修改；
>
> vision_service请求数据的输入，重载了preprocess函数，从请求的json中得到了各项输入，这里的图象是base64编码，我们直接调用python的包来进行解析的。

最终会生成一个mar相当于是exe启动文件一样的东西；

#### 基本原理和三种损失函数之间的演化和优势

Classic Identification：CNN提取特征-FC全连接输出类别-softmax损失进行分类，人脸比对实际上就是对FC全连接进行改进

**SOFTMAX的缺陷**

经过softmax的后特征呈现的是放射状分布的，以为它本质上计算的是feature属于每个类的概率，选择其中最大的类别作为预测概率：使用alpha(>=1)*Feature后，我们发现softmax的结果在这个类上的概率一定还是最大的。它本质上是增大了长度，我们在计算的过程中
$$
w·x = |w|·|x|cos(\theta)
$$
使用到了长度和角度特征，而最终分类特征的时候却只呈现为角度特征。

**从目标的角度来看**

（最小化类内距离，最大化类间距离）用-> 怎么把softmax变化到超球面上用角度去解决这个问题，这样的话我们可以将margin缩减成0，然后介绍我们分别用乘性的margin，还有外部加性的margin，以及内部加性margin对模型带来的葛总增益以及相关的局限性，

**PCN和MTCNN**

PCN针对的是旋转的人脸图像的情况，对这种图像情况下会更具备鲁棒性，所以更适应我们当下的这种基于Angular做分界面判别的情况，后续使用PCN对网络进行了改进。 取消了Landmark用角度的预测值来替代

MTCNN是P-Net R-Net O-Net，然后：https://zhuanlan.zhihu.com/p/58825924

### 项目3：针对长尾分布的教室图像学生表情、动作增量学习的研究

查看GCN的方法和EnAET介绍一下半监督和FSL中的研究工作和内容，然后通过现在的设想在对不平衡分布的数据进行后续的处理，以及通过小样本来对现在的网络进行增强，变成一个自更新的网络的部分。

#### （optinon）Help Data-Labeling：

基于Active Learning和Few-Shot-Learning（WSL等），思路的启发，提出在WSL的基础上使用ActiveLearning的思路，通过“effective”“vital”的信息Feedback，同时对于这些feedback的数据，我们以判断的形式来人类参与，也就是只控制输出的对与错，然后对于两种confirm，采取不同的策略，对判断错误的数据使用Hard-Task、resampling等“unbalance”的训练机制，来减缓算法的边际效应；通过这样的人机交互行为，期望能够快速的使得模型收敛，快速达到理论的性能上限，也就是通过减少从数据标记到模型产出整体过程中的人类参与行为，来降低再实际应用中的人类成本。

- 但是在实验中发现这种收敛加速的行为实际上**远远比不上self-supervised的过程**有效，这部分的收益就被掩盖了，确实是能够逼近理论的性能成本；
- 其中发现mix-up和sharpen的两个track对于这种场景来说是特别的有效的
- 基于我的评估指标，也就是从标注到判断需要的数据量中，时间成本收益远远不达到预期，但是确实能够更快的逼近收敛加速，但是分类这种任务本来就是个多选题，所以实际上成效并不明显
- 而基于这样的分析，以及对自监督和现实场景的了解，就引出了我后续的研究点，通过弱监督的这种特性来构建心累发现和通过类别增量的研究

#### 新类发现和模型的动态更新的研究

如何使得模型更好的自我发现，自我学习，自我质疑，实际上是一个模拟学习的过程，而像Meta FSL等，都是希望通过少量数据能够快速的对一个类别建立一个基础的认知，就像人脑一样，但是我觉得后续基于contrasive的self-supervised实际上是更贴合这种思考方式的，在我的理解看来就是通过多种数据，建立了一个认识世界的基本方式，也就是这样一个提取embedding的过程，然后通过FSL的方法快速的构建类别画像。

于是分析了现实世界和新类的两个特性，我们知道新类和常见类，实际上在初期是会呈现一个unbalance的特性，同时对于新类的发现，我们也需要网络有个比较好的置信度评估指标，我就提出了这样一个框架，然后再长尾分布的因果分析中提取了Multi-Head和使用moving-avg feature再测试过程中进行tde矫正的这样一个框架，然后通过Pool中的新类抽样混合类别，通过不均匀的hard-task来进行self-supervised和聚类分析，然后得到伪标签的新类，在这里就需要我们统一架构的小样本学习来快速的建立一个模型，再通过蒸馏架构的类别增量学习来进行实现的一个类别增量更新的过程，目前是已经建立了小样本的模型并提取出使用NIGD对置信度和小样本进行建模的这样一个过程。

- 这里首先整理一下NIG那部分框架我怎么提取出来的
- 然后整理一下Long-Tail的分析中的那一部分架构我是怎么提取出来的，还有怎么去讲，其中的去混杂和去中介的区分要

##### Long-tail的代码提取架构

主要是两点：认为实际上尾部数据不足以提供足够的样本来学习鲁棒的特征表达，所以认为rebalance那些简单的trick都不太好。我们认为头部的数据应该对尾部的特征数据来辅助，

**动量优化器**的方法就会给训练数据的时候带来shortcut从而因为数据分布对训练造成影响（但是动量对于模型收敛和下降速度比较重要）

**训练出来的特征对头部的偏移量**：优化器中包含了分布信息也有这个问题。

动量本身就是混淆因子，然后D就带来中介效应，

A. **去混杂** 去混淆训练

由于无法统计M的真实分布，就使用multi-head中的多重采样来近似，然后需要对受控组和非受控组，做归一化统一分布，用正则项来统一这个分布，也就是其中的。

B. **去中介**

就是基于最终特征的统计值，类似于安慰剂的对照试验来做的一个直接的剑法，来去除这个中介效应

##### NIG置信度分析的这一块

这一个论文的推导上是比较艰深的，我没有很好的掌握，但是基本的理念和实现上，是依赖一个NIG也就是深度学习模型的高斯分布假设(根据大数定理，当数据量够大的时候可以使用高斯分布去近似所有的分布)的预先验分布正太逆伽马分布：
$$
\Gamma(\alpha) = \int_{0}^{\infty} x^{a-1}e^{-x}dx
$$
$$
\operatorname{Pr}\left(\mu, \sigma^{2}\right)=\frac{\sqrt{\gamma}}{\sigma \sqrt{2 \pi}} \frac{\beta^{\alpha}}{\Gamma[\alpha]}\left(\frac{1}{\sigma^{2}}\right)^{\alpha+1} \exp \left[-\frac{-2 \beta+\gamma(\delta-\mu)^{2}}{2 \sigma^{2}}\right]
$$

去模拟高斯分布中的参数，以及该参数在NIG中的置信度，然后从而输出我们的判断结果，而在具体实现中，文章通过对分布的推导，然后通过代码，可以看出其中最关键的就是通过evidential layer和 evidential loss 来仿真这样一个用NIG分布来对深度模型进行建模的方法。

然后通过最后的四维的输出，我们可以估计出，偶然不确定性（数据层面），以及模型的不确定性（模型层面）
$$
数据误差估计：E(\sigma^2) = \beta / (\alpha-1); \\
模型误差估计：Var(\mu) = \frac{\beta}{v(\alpha-1) }
$$
从论文中我们知道，通过正太逆伽马分布假设的模型，在经过了MLE后，最终输出的四个维度，第一个维度实际上就是我们的预测结果，后面的第二个维度

- 需要讲最后的输出层建模成evidential层

  > 原本的网络输出的N-Dim Feature 我们需要将其dense链接到4*N个节点，然后做最终分析，将这个4*n dim 均匀拆分的话，我们可以得到[mu,logv,logalpha,logbeta]，然后对其中使用softplus后可以得到NIG的参数

  > 这里可以描述一下我们的两个进行整合的Plan，

- 然后我们需要在损失函数中，加入NIG_REG来帮助对置信度的回归分析，也就是在训练的时候，最小化错误样本的置信度。让evidential layer随着模型一起训练。

## 相关研究领域内容

### FSL的相关内容分析

**主要还是在之前的文档中，在这里就是记录一些容易忘记的东西**

经验风险最小化器（ML模型）不可靠 &　依靠先验知识的干预来进行模型的简历

相关的研究领域的辨析：

- Weakly Supervised Learning：是一个比较广的定义，只要标签的信息量比较weak，都可以算把
- semi-supervised Learning：主要利用的是未标注的数据来作为先验知识，进而解决标签量少的问题
- Activate Learning：从未标注数据中选择能对模型造成最大增益的数据来进行人机交互，通过人类的标注来帮助模型使用这些数据，在尽可能少的数据使用的情况下来快速的构建一个收敛的模型；
- Imbalance Learning：数据分布不均衡，比如正负样例严重失衡的情况，resample reweight two-stage
- Transfer Learning：实际上更像是一种技术手段，是一种domin adaptation的操作，将模型向相似域转移，这种方法是利用了一个训练好的模型的参数来作为先验从而对我们的FSL来制造增益的一个行为。
- Meta-Learning：这个在后续总结，是一个大块，好像叫做learning to learn把。

三类主要的解决思路：

- 数据：变换训练集中的数据、变换弱监督或者无监督的数据来进行使用，变化类别相似的数据集（使用GAN来进行标签映射）

- 算法：基于算法的方法实际上就是在优化算法上做出的改进：主要从两点出发

  1. 良好的模型初值：其中涉及到如何避免过拟合（使用一堆正则化策略来优化）
  2. 优化器中良好的搜索步骤：不适用梯度下降，使用一种可以直接输出更新的优化器

- 模型：实际上基本思路是通过模型来缩减解空间，使得我们能在假设空间中更快的搜索到解，从而只需要少量的数据（先验知识的利用）；

  > 简单的模型无法仿真真实复杂的问题，复杂的模型受限于缺失的数据；于是就是以缩减假设空间，来进行优化：实际上很多方法都是通过在别的任务中进行训练从而得到先验知识来对当前任务进行补充的方法；
  >
  > 训练过程中经常涉及到的就是task-specific和share的参数共享策略的区分；
  >
  > 或者使用正则化来约束模型之间的参数分布相似性
  >
  > ![image-20200520212452504](https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20200520212452504.png)



### self-supervised的相关内容分析

**主要参考之前的笔记和相关的md，在这里就是简单的加强一下记忆力**

首先搞清楚时间节点：Mix-match-EnAet - Simclr -Simclr v2

然后还有MoCo系列的那一些，一起整理一下

大环境下实际上主流的方法还是Transfer Learning

**首先SimCLR-V2**

**最大化同一图像的不同增强版本之间的表征一致性，和与其余的负样例的相似对对比损失也要尽可能的大**需要大量的负样本对



Google的SimCLR就是基于Data-Augmentation的这种self-supervised的思路，结合Contrastive Learning，从一致性来指导网络从数据集中学习到一个较好的通用表征。

- 扩容，**project head**的必要性
- fine tune 的修改
- student和teacher机制

![image-20210310231033429](https://raw.githubusercontent.com/AikenH/md-image/master/img/image-20210310231033429.png)

**然后MixMatch-（FixMatch）-EnAET：**

一种整体性的半监督学习的方法，是当时半监督学习的一个集大成，对当时的方法进行了测试和整合，然后给出了一个更为有效的方法。

当时主流的几种方法：

- 熵损失最小化，让模型对无标签样本的预测置信度高（使用sharpen来对标签进行处理）
- 连续性预测标准：对于受到扰动的样本，有稳定的模型输出

该模型就是通过这两个思路去进行算法的改进

具体实现：

- 对数据做增强增广，特别是结合MixUp的思路，模型预测后取平均然后做一个sharpen,得到的一个pseudo label

**ENAET**

实际上有点像是使用MixMatch和自监督学习的混合，他在具体实现的过程中将task-specific和task-agnostic的过程耦合在一起训练，通过一个AET的自监督的过程来知道Encoder的学习，然后通过最终的标签来训练classifier和encoder。

同时还加入了KL散度（不同的transformation之间的分布一致性损失）的正则项来对网络进行进一步的评估和处理。

**实验中存在的问题：**

1. 小样本数据不均衡导致的准确率严重下降

2. 梯度爆炸

   1. 对于不同Transformation的损失归一化处理
   2. 检查lr

**数据增强：**

1. projective
2. affine
3. ccbs
4. mixup



**Simclr** 和moco v1-v2 （simple Siamese Network）都认为负样例是很重要的

**moco**的动量更新是为了队列中的参数变化变得缓和下来来简单训练，其中的损失函数实际上也是一种相似性对量，衡量匹配之家你的关系

***InfoNCE***

**没有负样本会陷入平凡解**

**BYOL**试图破除负样本迷信，在projector head后面添加了一个predictor，去学习online encoder到target encoder之间的映射，而不是去拉近正样本对之间的距离

**SiaSiam** 在BYOL上做减法，直接让target encoder 对应 online encoder，去除了动量更新的这块，predictor+stop-gradinent是训练的充分条件

**Barlow Twins**

[参考链接地址](https://zhuanlan.zhihu.com/p/355523266)

Barlow Twins 既没有使用负样本，也没有动量更新的网络，也没有predictor和stop gradient操作。Twins 所做的是换了一种视角去学习表示，从embeddig本身出发，而不是从样本出发。优化目标是使得不同视角下的特征的相关矩阵接近恒等矩阵，即让不同的维度的特征尽量表示不同的信息，从而提升特征的表征能力。这种做法，感觉和以前传统降维（如PCA）的方法是有共通之处的。

![preview](https://raw.githubusercontent.com/AikenH/md-image/master/img/v2-221c68142f83b4ebbb774d9e5b2436c3_r.jpg)

就是从样本相关的层面提升到特征相关的层面了，Simclr和Moco要用queue的方法维护很大的batchsize，这个方法则是需要很大的特征维度



### META Learning

https://wei-tianhao.github.io/blog/2019/09/17/meta-learning.html#%E5%83%8F%E6%B5%8B%E8%AF%95%E4%B8%80%E6%A0%B7%E8%AE%AD%E7%BB%83

以及Onenote的两个大概思路即可

### 增量学习的基本方法和思路

跳转Onenote进行复习，主要是前两三个,知识蒸馏的结构，损失设计

### Unbalance Learning 的基本方法和思路

跳转Onenote中进行复习

**Reweighting 代价敏感重加权**

**ReSampled方法**

two-stage方法：在训练集上训练feature，在测试集上训练classifier

两个因果分析的方法：

### Active Learning的基本策略

Active Learning 和 Semi-Supervised中的这种天然温和的特性实际上是一个比较重要的点。

- 随机采样策略

- 不确定性策略：选出最不确定的样本，也就是对应的hard-task这样的任务

- 熵值最大化元素，优先筛选具有最大熵的样本，熵的公式还有树的剪切的公式
  $$
  EntropyScore = -\sum_{i=1}^{C}pi   ·log(pi)
  $$

- 委员会投票：使用多个模型进行预测筛选，选出最不一致的样本进行标注

- 方差最小...

- 预测结果的概率表示中值最小的



